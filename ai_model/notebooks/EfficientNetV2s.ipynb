{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d411747808cb49799199d06fcf858480":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a9fd92290874949be12ae02b53c0e60","IPY_MODEL_45eaebb729f04a32b639e3193dca5078","IPY_MODEL_52ad3d0307954ef1bfb66012a7d6f1e2"],"layout":"IPY_MODEL_6caecd4031cd41398574df85ebc162e3"}},"4a9fd92290874949be12ae02b53c0e60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aad1622b6fd24b8e92f76c5cb95a078d","placeholder":"​","style":"IPY_MODEL_53133bd62dc844ed9161c14c376b9c97","value":"model.safetensors: 100%"}},"45eaebb729f04a32b639e3193dca5078":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1a52c2ad83b44faa79f964e9353e75c","max":86523256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49e5134a3a0b4a65b412bf1d18b0e4ed","value":86523256}},"52ad3d0307954ef1bfb66012a7d6f1e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e21402127fe475b887b9ddd19e726be","placeholder":"​","style":"IPY_MODEL_c52a875f6bec4d07a3ee34059e4e5f32","value":" 86.5M/86.5M [00:00&lt;00:00, 167MB/s]"}},"6caecd4031cd41398574df85ebc162e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad1622b6fd24b8e92f76c5cb95a078d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53133bd62dc844ed9161c14c376b9c97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1a52c2ad83b44faa79f964e9353e75c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49e5134a3a0b4a65b412bf1d18b0e4ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e21402127fe475b887b9ddd19e726be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52a875f6bec4d07a3ee34059e4e5f32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"30--eSLig-lE","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d411747808cb49799199d06fcf858480","4a9fd92290874949be12ae02b53c0e60","45eaebb729f04a32b639e3193dca5078","52ad3d0307954ef1bfb66012a7d6f1e2","6caecd4031cd41398574df85ebc162e3","aad1622b6fd24b8e92f76c5cb95a078d","53133bd62dc844ed9161c14c376b9c97","c1a52c2ad83b44faa79f964e9353e75c","49e5134a3a0b4a65b412bf1d18b0e4ed","9e21402127fe475b887b9ddd19e726be","c52a875f6bec4d07a3ee34059e4e5f32"]},"executionInfo":{"status":"ok","timestamp":1753430371092,"user_tz":-480,"elapsed":2571556,"user":{"displayName":"李柏駿","userId":"07522532513227506161"}},"outputId":"2585152a-7f45-404c-d94e-89005e6f3033"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.7.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.17)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.7.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.7.14)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","環境設置完成！\n","正在複製資料集ZIP檔案到Colab...\n","✓ ZIP檔案複製完成\n","正在解壓縮資料集...\n","✓ 資料集解壓縮完成\n","✓ 已清理臨時ZIP檔案\n","檢查本地資料集路徑:\n","✓ 訓練資料夾存在: /content/EfficientNet_dataset/train\n","✓ 驗證資料夾存在: /content/EfficientNet_dataset/valid\n","✓ 測試資料夾存在: /content/EfficientNet_dataset/test\n","\n","訓練資料集分析:\n","==================================================\n","  S: 1891 張圖片\n","  V: 2550 張圖片\n","  F: 2168 張圖片\n","  總計: 6609 張圖片\n","  類別分布: {'S': 1891, 'V': 2550, 'F': 2168}\n","\n","驗證資料集分析:\n","==================================================\n","  S: 1314 張圖片\n","  V: 1882 張圖片\n","  F: 1396 張圖片\n","  總計: 4592 張圖片\n","  類別分布: {'S': 1314, 'V': 1882, 'F': 1396}\n","\n","測試資料集分析:\n","==================================================\n","  S: 1635 張圖片\n","  V: 1683 張圖片\n","  F: 1345 張圖片\n","  總計: 4663 張圖片\n","  類別分布: {'S': 1635, 'V': 1683, 'F': 1345}\n","\n","最終資料集統計:\n","訓練樣本數: 6609\n","驗證樣本數: 4592\n","測試樣本數: 4663\n","類別數: 3\n","類別名稱: ['F', 'S', 'V']\n","批次大小: 24\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d411747808cb49799199d06fcf858480"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","模型架構分析:\n","模型: EfficientNetV2-S\n","使用設備: cuda\n","總參數數量: 20,181,331\n","可訓練參數: 20,181,331\n","類別映射: {0: 'F', 1: 'S', 2: 'V'}\n","類別權重: {'F': np.float32(1.0161439), 'S': np.float32(1.1649921), 'V': np.float32(0.8639216)}\n","開始訓練異物檢測模型...\n","======================================================================\n","\n","Epoch 1/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 2.3218\n","  Batch 20/276, Loss: 1.2437\n","  Batch 40/276, Loss: 1.0537\n","  Batch 60/276, Loss: 0.8364\n","  Batch 80/276, Loss: 0.7215\n","  Batch 100/276, Loss: 0.6526\n","  Batch 120/276, Loss: 0.5816\n","  Batch 140/276, Loss: 0.5453\n","  Batch 160/276, Loss: 0.4981\n","  Batch 180/276, Loss: 0.4576\n","  Batch 200/276, Loss: 0.4308\n","  Batch 220/276, Loss: 0.4107\n","  Batch 240/276, Loss: 0.3835\n","  Batch 260/276, Loss: 0.3694\n","訓練指標:\n","  Loss: 0.3582, Acc: 0.9098, F1: 0.9098\n","  Precision: 0.9098, Recall: 0.9098\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.1432, Acc: 0.9560, F1: 0.9562\n","  Precision: 0.9576, Recall: 0.9560\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 100.28秒\n","★ 新的最佳模型! F1: 0.9562, Acc: 0.9560\n","\n","Epoch 2/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0801\n","  Batch 20/276, Loss: 0.0887\n","  Batch 40/276, Loss: 0.1161\n","  Batch 60/276, Loss: 0.1149\n","  Batch 80/276, Loss: 0.1104\n","  Batch 100/276, Loss: 0.1084\n","  Batch 120/276, Loss: 0.1088\n","  Batch 140/276, Loss: 0.1183\n","  Batch 160/276, Loss: 0.1183\n","  Batch 180/276, Loss: 0.1283\n","  Batch 200/276, Loss: 0.1269\n","  Batch 220/276, Loss: 0.1253\n","  Batch 240/276, Loss: 0.1201\n","  Batch 260/276, Loss: 0.1203\n","訓練指標:\n","  Loss: 0.1243, Acc: 0.9631, F1: 0.9631\n","  Precision: 0.9631, Recall: 0.9631\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0707, Acc: 0.9769, F1: 0.9768\n","  Precision: 0.9777, Recall: 0.9769\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 98.82秒\n","★ 新的最佳模型! F1: 0.9768, Acc: 0.9769\n","\n","Epoch 3/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.3844\n","  Batch 20/276, Loss: 0.1143\n","  Batch 40/276, Loss: 0.1051\n","  Batch 60/276, Loss: 0.0869\n","  Batch 80/276, Loss: 0.0823\n","  Batch 100/276, Loss: 0.0785\n","  Batch 120/276, Loss: 0.0744\n","  Batch 140/276, Loss: 0.0693\n","  Batch 160/276, Loss: 0.0739\n","  Batch 180/276, Loss: 0.0761\n","  Batch 200/276, Loss: 0.0764\n","  Batch 220/276, Loss: 0.0759\n","  Batch 240/276, Loss: 0.0723\n","  Batch 260/276, Loss: 0.0699\n","訓練指標:\n","  Loss: 0.0693, Acc: 0.9821, F1: 0.9821\n","  Precision: 0.9821, Recall: 0.9821\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0403, Acc: 0.9865, F1: 0.9865\n","  Precision: 0.9865, Recall: 0.9865\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 100.07秒\n","★ 新的最佳模型! F1: 0.9865, Acc: 0.9865\n","\n","Epoch 4/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0021\n","  Batch 20/276, Loss: 0.1078\n","  Batch 40/276, Loss: 0.1083\n","  Batch 60/276, Loss: 0.1055\n","  Batch 80/276, Loss: 0.0865\n","  Batch 100/276, Loss: 0.0776\n","  Batch 120/276, Loss: 0.0678\n","  Batch 140/276, Loss: 0.0663\n","  Batch 160/276, Loss: 0.0667\n","  Batch 180/276, Loss: 0.0678\n","  Batch 200/276, Loss: 0.0669\n","  Batch 220/276, Loss: 0.0662\n","  Batch 240/276, Loss: 0.0687\n","  Batch 260/276, Loss: 0.0674\n","訓練指標:\n","  Loss: 0.0652, Acc: 0.9817, F1: 0.9817\n","  Precision: 0.9817, Recall: 0.9817\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0284, Acc: 0.9887, F1: 0.9887\n","  Precision: 0.9887, Recall: 0.9887\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.47秒\n","★ 新的最佳模型! F1: 0.9887, Acc: 0.9887\n","\n","Epoch 5/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0319\n","  Batch 20/276, Loss: 0.0640\n","  Batch 40/276, Loss: 0.0682\n","  Batch 60/276, Loss: 0.0806\n","  Batch 80/276, Loss: 0.0827\n","  Batch 100/276, Loss: 0.0823\n","  Batch 120/276, Loss: 0.0794\n","  Batch 140/276, Loss: 0.0779\n","  Batch 160/276, Loss: 0.0728\n","  Batch 180/276, Loss: 0.0677\n","  Batch 200/276, Loss: 0.0619\n","  Batch 220/276, Loss: 0.0623\n","  Batch 240/276, Loss: 0.0601\n","  Batch 260/276, Loss: 0.0608\n","訓練指標:\n","  Loss: 0.0639, Acc: 0.9832, F1: 0.9832\n","  Precision: 0.9832, Recall: 0.9832\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.1138, Acc: 0.9804, F1: 0.9805\n","  Precision: 0.9807, Recall: 0.9804\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 100.36秒\n","\n","Epoch 6/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0105\n","  Batch 20/276, Loss: 0.0366\n","  Batch 40/276, Loss: 0.0379\n","  Batch 60/276, Loss: 0.0476\n","  Batch 80/276, Loss: 0.0407\n","  Batch 100/276, Loss: 0.0357\n","  Batch 120/276, Loss: 0.0325\n","  Batch 140/276, Loss: 0.0447\n","  Batch 160/276, Loss: 0.0488\n","  Batch 180/276, Loss: 0.0462\n","  Batch 200/276, Loss: 0.0453\n","  Batch 220/276, Loss: 0.0455\n","  Batch 240/276, Loss: 0.0446\n","  Batch 260/276, Loss: 0.0447\n","訓練指標:\n","  Loss: 0.0441, Acc: 0.9868, F1: 0.9868\n","  Precision: 0.9868, Recall: 0.9868\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0317, Acc: 0.9906, F1: 0.9906\n","  Precision: 0.9907, Recall: 0.9906\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.21秒\n","★ 新的最佳模型! F1: 0.9906, Acc: 0.9906\n","\n","Epoch 7/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0003\n","  Batch 20/276, Loss: 0.0420\n","  Batch 40/276, Loss: 0.0450\n","  Batch 60/276, Loss: 0.0459\n","  Batch 80/276, Loss: 0.0392\n","  Batch 100/276, Loss: 0.0389\n","  Batch 120/276, Loss: 0.0408\n","  Batch 140/276, Loss: 0.0415\n","  Batch 160/276, Loss: 0.0397\n","  Batch 180/276, Loss: 0.0412\n","  Batch 200/276, Loss: 0.0384\n","  Batch 220/276, Loss: 0.0370\n","  Batch 240/276, Loss: 0.0371\n","  Batch 260/276, Loss: 0.0387\n","訓練指標:\n","  Loss: 0.0395, Acc: 0.9887, F1: 0.9886\n","  Precision: 0.9886, Recall: 0.9887\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0226, Acc: 0.9917, F1: 0.9917\n","  Precision: 0.9918, Recall: 0.9917\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.10秒\n","★ 新的最佳模型! F1: 0.9917, Acc: 0.9917\n","\n","Epoch 8/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.1747\n","  Batch 20/276, Loss: 0.0228\n","  Batch 40/276, Loss: 0.0268\n","  Batch 60/276, Loss: 0.0252\n","  Batch 80/276, Loss: 0.0271\n","  Batch 100/276, Loss: 0.0287\n","  Batch 120/276, Loss: 0.0254\n","  Batch 140/276, Loss: 0.0273\n","  Batch 160/276, Loss: 0.0321\n","  Batch 180/276, Loss: 0.0337\n","  Batch 200/276, Loss: 0.0307\n","  Batch 220/276, Loss: 0.0291\n","  Batch 240/276, Loss: 0.0299\n","  Batch 260/276, Loss: 0.0289\n","訓練指標:\n","  Loss: 0.0296, Acc: 0.9926, F1: 0.9926\n","  Precision: 0.9926, Recall: 0.9926\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0256, Acc: 0.9948, F1: 0.9948\n","  Precision: 0.9948, Recall: 0.9948\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.60秒\n","★ 新的最佳模型! F1: 0.9948, Acc: 0.9948\n","\n","Epoch 9/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0001\n","  Batch 20/276, Loss: 0.0447\n","  Batch 40/276, Loss: 0.0328\n","  Batch 60/276, Loss: 0.0270\n","  Batch 80/276, Loss: 0.0315\n","  Batch 100/276, Loss: 0.0317\n","  Batch 120/276, Loss: 0.0364\n","  Batch 140/276, Loss: 0.0389\n","  Batch 160/276, Loss: 0.0403\n","  Batch 180/276, Loss: 0.0431\n","  Batch 200/276, Loss: 0.0438\n","  Batch 220/276, Loss: 0.0467\n","  Batch 240/276, Loss: 0.0480\n","  Batch 260/276, Loss: 0.0453\n","訓練指標:\n","  Loss: 0.0448, Acc: 0.9885, F1: 0.9885\n","  Precision: 0.9885, Recall: 0.9885\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0260, Acc: 0.9904, F1: 0.9904\n","  Precision: 0.9905, Recall: 0.9904\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 103.24秒\n","\n","Epoch 10/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0089\n","  Batch 20/276, Loss: 0.0254\n","  Batch 40/276, Loss: 0.0216\n","  Batch 60/276, Loss: 0.0175\n","  Batch 80/276, Loss: 0.0268\n","  Batch 100/276, Loss: 0.0429\n","  Batch 120/276, Loss: 0.0399\n","  Batch 140/276, Loss: 0.0365\n","  Batch 160/276, Loss: 0.0365\n","  Batch 180/276, Loss: 0.0338\n","  Batch 200/276, Loss: 0.0339\n","  Batch 220/276, Loss: 0.0315\n","  Batch 240/276, Loss: 0.0293\n","  Batch 260/276, Loss: 0.0295\n","訓練指標:\n","  Loss: 0.0309, Acc: 0.9924, F1: 0.9924\n","  Precision: 0.9924, Recall: 0.9924\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0300, Acc: 0.9946, F1: 0.9946\n","  Precision: 0.9946, Recall: 0.9946\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 100.59秒\n","\n","Epoch 11/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0007\n","  Batch 20/276, Loss: 0.0097\n","  Batch 40/276, Loss: 0.0304\n","  Batch 60/276, Loss: 0.0435\n","  Batch 80/276, Loss: 0.0386\n","  Batch 100/276, Loss: 0.0317\n","  Batch 120/276, Loss: 0.0277\n","  Batch 140/276, Loss: 0.0269\n","  Batch 160/276, Loss: 0.0264\n","  Batch 180/276, Loss: 0.0265\n","  Batch 200/276, Loss: 0.0267\n","  Batch 220/276, Loss: 0.0260\n","  Batch 240/276, Loss: 0.0253\n","  Batch 260/276, Loss: 0.0267\n","訓練指標:\n","  Loss: 0.0308, Acc: 0.9920, F1: 0.9920\n","  Precision: 0.9920, Recall: 0.9920\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0186, Acc: 0.9935, F1: 0.9935\n","  Precision: 0.9935, Recall: 0.9935\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 98.77秒\n","\n","Epoch 12/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0014\n","  Batch 20/276, Loss: 0.0465\n","  Batch 40/276, Loss: 0.0271\n","  Batch 60/276, Loss: 0.0214\n","  Batch 80/276, Loss: 0.0207\n","  Batch 100/276, Loss: 0.0269\n","  Batch 120/276, Loss: 0.0263\n","  Batch 140/276, Loss: 0.0271\n","  Batch 160/276, Loss: 0.0249\n","  Batch 180/276, Loss: 0.0251\n","  Batch 200/276, Loss: 0.0232\n","  Batch 220/276, Loss: 0.0221\n","  Batch 240/276, Loss: 0.0226\n","  Batch 260/276, Loss: 0.0259\n","訓練指標:\n","  Loss: 0.0319, Acc: 0.9932, F1: 0.9932\n","  Precision: 0.9932, Recall: 0.9932\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0541, Acc: 0.9893, F1: 0.9893\n","  Precision: 0.9893, Recall: 0.9893\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.73秒\n","\n","Epoch 13/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0606\n","  Batch 20/276, Loss: 0.0582\n","  Batch 40/276, Loss: 0.0500\n","  Batch 60/276, Loss: 0.0424\n","  Batch 80/276, Loss: 0.0422\n","  Batch 100/276, Loss: 0.0397\n","  Batch 120/276, Loss: 0.0350\n","  Batch 140/276, Loss: 0.0508\n","  Batch 160/276, Loss: 0.0530\n","  Batch 180/276, Loss: 0.0535\n","  Batch 200/276, Loss: 0.0555\n","  Batch 220/276, Loss: 0.0510\n","  Batch 240/276, Loss: 0.0472\n","  Batch 260/276, Loss: 0.0461\n","訓練指標:\n","  Loss: 0.0441, Acc: 0.9891, F1: 0.9891\n","  Precision: 0.9891, Recall: 0.9891\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0222, Acc: 0.9930, F1: 0.9930\n","  Precision: 0.9931, Recall: 0.9930\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.23秒\n","\n","Epoch 14/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0147\n","  Batch 20/276, Loss: 0.0215\n","  Batch 40/276, Loss: 0.0151\n","  Batch 60/276, Loss: 0.0138\n","  Batch 80/276, Loss: 0.0136\n","  Batch 100/276, Loss: 0.0243\n","  Batch 120/276, Loss: 0.0289\n","  Batch 140/276, Loss: 0.0298\n","  Batch 160/276, Loss: 0.0271\n","  Batch 180/276, Loss: 0.0263\n","  Batch 200/276, Loss: 0.0263\n","  Batch 220/276, Loss: 0.0246\n","  Batch 240/276, Loss: 0.0236\n","  Batch 260/276, Loss: 0.0247\n","訓練指標:\n","  Loss: 0.0239, Acc: 0.9938, F1: 0.9938\n","  Precision: 0.9938, Recall: 0.9938\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0065, Acc: 0.9976, F1: 0.9976\n","  Precision: 0.9976, Recall: 0.9976\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.36秒\n","★ 新的最佳模型! F1: 0.9976, Acc: 0.9976\n","\n","Epoch 15/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0008\n","  Batch 20/276, Loss: 0.0241\n","  Batch 40/276, Loss: 0.0327\n","  Batch 60/276, Loss: 0.0242\n","  Batch 80/276, Loss: 0.0247\n","  Batch 100/276, Loss: 0.0238\n","  Batch 120/276, Loss: 0.0230\n","  Batch 140/276, Loss: 0.0205\n","  Batch 160/276, Loss: 0.0223\n","  Batch 180/276, Loss: 0.0229\n","  Batch 200/276, Loss: 0.0227\n","  Batch 220/276, Loss: 0.0270\n","  Batch 240/276, Loss: 0.0269\n","  Batch 260/276, Loss: 0.0288\n","訓練指標:\n","  Loss: 0.0304, Acc: 0.9918, F1: 0.9918\n","  Precision: 0.9918, Recall: 0.9918\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0379, Acc: 0.9891, F1: 0.9891\n","  Precision: 0.9892, Recall: 0.9891\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 100.06秒\n","\n","Epoch 16/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0036\n","  Batch 20/276, Loss: 0.0105\n","  Batch 40/276, Loss: 0.0065\n","  Batch 60/276, Loss: 0.0048\n","  Batch 80/276, Loss: 0.0120\n","  Batch 100/276, Loss: 0.0446\n","  Batch 120/276, Loss: 0.0404\n","  Batch 140/276, Loss: 0.0389\n","  Batch 160/276, Loss: 0.0379\n","  Batch 180/276, Loss: 0.0369\n","  Batch 200/276, Loss: 0.0364\n","  Batch 220/276, Loss: 0.0348\n","  Batch 240/276, Loss: 0.0326\n","  Batch 260/276, Loss: 0.0311\n","訓練指標:\n","  Loss: 0.0311, Acc: 0.9946, F1: 0.9946\n","  Precision: 0.9946, Recall: 0.9946\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0307, Acc: 0.9898, F1: 0.9898\n","  Precision: 0.9898, Recall: 0.9898\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 98.69秒\n","\n","Epoch 17/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0011\n","  Batch 20/276, Loss: 0.0140\n","  Batch 40/276, Loss: 0.0123\n","  Batch 60/276, Loss: 0.0103\n","  Batch 80/276, Loss: 0.0096\n","  Batch 100/276, Loss: 0.0127\n","  Batch 120/276, Loss: 0.0166\n","  Batch 140/276, Loss: 0.0155\n","  Batch 160/276, Loss: 0.0177\n","  Batch 180/276, Loss: 0.0183\n","  Batch 200/276, Loss: 0.0182\n","  Batch 220/276, Loss: 0.0190\n","  Batch 240/276, Loss: 0.0190\n","  Batch 260/276, Loss: 0.0192\n","訓練指標:\n","  Loss: 0.0217, Acc: 0.9939, F1: 0.9939\n","  Precision: 0.9939, Recall: 0.9939\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0443, Acc: 0.9889, F1: 0.9889\n","  Precision: 0.9891, Recall: 0.9889\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.24秒\n","\n","Epoch 18/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0013\n","  Batch 20/276, Loss: 0.0041\n","  Batch 40/276, Loss: 0.0134\n","  Batch 60/276, Loss: 0.0196\n","  Batch 80/276, Loss: 0.0317\n","  Batch 100/276, Loss: 0.0271\n","  Batch 120/276, Loss: 0.0246\n","  Batch 140/276, Loss: 0.0242\n","  Batch 160/276, Loss: 0.0245\n","  Batch 180/276, Loss: 0.0269\n","  Batch 200/276, Loss: 0.0292\n","  Batch 220/276, Loss: 0.0282\n","  Batch 240/276, Loss: 0.0274\n","  Batch 260/276, Loss: 0.0263\n","訓練指標:\n","  Loss: 0.0265, Acc: 0.9929, F1: 0.9929\n","  Precision: 0.9929, Recall: 0.9929\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0084, Acc: 0.9974, F1: 0.9974\n","  Precision: 0.9974, Recall: 0.9974\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 98.99秒\n","\n","Epoch 19/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.2087\n","  Batch 20/276, Loss: 0.0226\n","  Batch 40/276, Loss: 0.0504\n","  Batch 60/276, Loss: 0.0463\n","  Batch 80/276, Loss: 0.0388\n","  Batch 100/276, Loss: 0.0345\n","  Batch 120/276, Loss: 0.0319\n","  Batch 140/276, Loss: 0.0303\n","  Batch 160/276, Loss: 0.0278\n","  Batch 180/276, Loss: 0.0293\n","  Batch 200/276, Loss: 0.0292\n","  Batch 220/276, Loss: 0.0267\n","  Batch 240/276, Loss: 0.0273\n","  Batch 260/276, Loss: 0.0268\n","訓練指標:\n","  Loss: 0.0265, Acc: 0.9927, F1: 0.9927\n","  Precision: 0.9927, Recall: 0.9927\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0330, Acc: 0.9928, F1: 0.9928\n","  Precision: 0.9929, Recall: 0.9928\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 98.75秒\n","\n","Epoch 20/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0005\n","  Batch 20/276, Loss: 0.0162\n","  Batch 40/276, Loss: 0.0258\n","  Batch 60/276, Loss: 0.0191\n","  Batch 80/276, Loss: 0.0150\n","  Batch 100/276, Loss: 0.0152\n","  Batch 120/276, Loss: 0.0131\n","  Batch 140/276, Loss: 0.0121\n","  Batch 160/276, Loss: 0.0112\n","  Batch 180/276, Loss: 0.0126\n","  Batch 200/276, Loss: 0.0124\n","  Batch 220/276, Loss: 0.0125\n","  Batch 240/276, Loss: 0.0131\n","  Batch 260/276, Loss: 0.0128\n","訓練指標:\n","  Loss: 0.0129, Acc: 0.9958, F1: 0.9958\n","  Precision: 0.9958, Recall: 0.9958\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0268, Acc: 0.9961, F1: 0.9961\n","  Precision: 0.9961, Recall: 0.9961\n","  ROC-AUC: 0.0000\n","學習率: 0.001000, 時間: 99.76秒\n","\n","Epoch 21/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0039\n","  Batch 20/276, Loss: 0.0211\n","  Batch 40/276, Loss: 0.0208\n","  Batch 60/276, Loss: 0.0233\n","  Batch 80/276, Loss: 0.0182\n","  Batch 100/276, Loss: 0.0165\n","  Batch 120/276, Loss: 0.0175\n","  Batch 140/276, Loss: 0.0153\n","  Batch 160/276, Loss: 0.0136\n","  Batch 180/276, Loss: 0.0122\n","  Batch 200/276, Loss: 0.0114\n","  Batch 220/276, Loss: 0.0105\n","  Batch 240/276, Loss: 0.0096\n","  Batch 260/276, Loss: 0.0089\n","訓練指標:\n","  Loss: 0.0085, Acc: 0.9982, F1: 0.9982\n","  Precision: 0.9982, Recall: 0.9982\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0103, Acc: 0.9959, F1: 0.9959\n","  Precision: 0.9959, Recall: 0.9959\n","  ROC-AUC: 0.0000\n","學習率: 0.000500, 時間: 99.60秒\n","\n","Epoch 22/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0048\n","  Batch 20/276, Loss: 0.0004\n","  Batch 40/276, Loss: 0.0004\n","  Batch 60/276, Loss: 0.0003\n","  Batch 80/276, Loss: 0.0027\n","  Batch 100/276, Loss: 0.0026\n","  Batch 120/276, Loss: 0.0036\n","  Batch 140/276, Loss: 0.0031\n","  Batch 160/276, Loss: 0.0028\n","  Batch 180/276, Loss: 0.0025\n","  Batch 200/276, Loss: 0.0033\n","  Batch 220/276, Loss: 0.0031\n","  Batch 240/276, Loss: 0.0045\n","  Batch 260/276, Loss: 0.0045\n","訓練指標:\n","  Loss: 0.0044, Acc: 0.9988, F1: 0.9988\n","  Precision: 0.9988, Recall: 0.9988\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0155, Acc: 0.9948, F1: 0.9948\n","  Precision: 0.9948, Recall: 0.9948\n","  ROC-AUC: 0.0000\n","學習率: 0.000500, 時間: 100.41秒\n","\n","Epoch 23/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0007\n","  Batch 20/276, Loss: 0.0003\n","  Batch 40/276, Loss: 0.0014\n","  Batch 60/276, Loss: 0.0024\n","  Batch 80/276, Loss: 0.0025\n","  Batch 100/276, Loss: 0.0035\n","  Batch 120/276, Loss: 0.0042\n","  Batch 140/276, Loss: 0.0036\n","  Batch 160/276, Loss: 0.0043\n","  Batch 180/276, Loss: 0.0043\n","  Batch 200/276, Loss: 0.0049\n","  Batch 220/276, Loss: 0.0045\n","  Batch 240/276, Loss: 0.0049\n","  Batch 260/276, Loss: 0.0051\n","訓練指標:\n","  Loss: 0.0056, Acc: 0.9979, F1: 0.9979\n","  Precision: 0.9979, Recall: 0.9979\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0143, Acc: 0.9967, F1: 0.9967\n","  Precision: 0.9967, Recall: 0.9967\n","  ROC-AUC: 0.0000\n","學習率: 0.000500, 時間: 99.52秒\n","\n","Epoch 24/30\n","----------------------------------------------------------------------\n","  Batch 0/276, Loss: 0.0005\n","  Batch 20/276, Loss: 0.0011\n","  Batch 40/276, Loss: 0.0071\n","  Batch 60/276, Loss: 0.0053\n","  Batch 80/276, Loss: 0.0043\n","  Batch 100/276, Loss: 0.0035\n","  Batch 120/276, Loss: 0.0055\n","  Batch 140/276, Loss: 0.0050\n","  Batch 160/276, Loss: 0.0045\n","  Batch 180/276, Loss: 0.0043\n","  Batch 200/276, Loss: 0.0051\n","  Batch 220/276, Loss: 0.0047\n","  Batch 240/276, Loss: 0.0054\n","  Batch 260/276, Loss: 0.0051\n","訓練指標:\n","  Loss: 0.0052, Acc: 0.9988, F1: 0.9988\n","  Precision: 0.9988, Recall: 0.9988\n","  ROC-AUC: 0.0000\n","驗證指標:\n","  Loss: 0.0081, Acc: 0.9978, F1: 0.9978\n","  Precision: 0.9978, Recall: 0.9978\n","  ROC-AUC: 0.0000\n","學習率: 0.000500, 時間: 100.01秒\n","★ 新的最佳模型! F1: 0.9978, Acc: 0.9978\n","Early stopping triggered at epoch 24\n","\n","訓練完成! 總時間: 40.10 分鐘\n","最佳驗證F1分數: 0.9978\n","最佳驗證準確率: 0.9978\n","已載入最佳模型進行測試\n","\n","進行測試集評估...\n","\n","測試集最終結果:\n","==================================================\n","Accuracy: 0.9949\n","Balanced Accuracy: 0.9951\n","Precision: 0.9949\n","Recall: 0.9949\n","F1-Score: 0.9949\n","Specificity: 0.0000\n","Sensitivity: 0.0000\n","\n","推論速度統計:\n","平均FPS: 477.99\n","每張圖片推論時間: 2.09 ms\n","總推論時間: 9.7555 秒\n","總測試樣本數: 4663\n"]}],"source":["# 連接Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 安裝必要套件\n","!pip install torch torchvision torchaudio\n","!pip install timm\n","!pip install matplotlib seaborn\n","!pip install scikit-learn\n","\n","# 導入所有必要的函式庫\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","import timm\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from PIL import Image\n","import time\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    confusion_matrix, classification_report, roc_curve, auc,\n","    precision_recall_curve, average_precision_score, matthews_corrcoef,\n","    cohen_kappa_score, balanced_accuracy_score\n",")\n","from sklearn.utils.class_weight import compute_class_weight\n","import pandas as pd\n","import json\n","import zipfile\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"環境設置完成！\")\n","\n","# 複製並解壓資料集到本地\n","import shutil\n","import zipfile\n","\n","print(\"正在複製資料集ZIP檔案到Colab...\")\n","zip_source = '/content/drive/My Drive/DualStage-DefectAI/資料集/EfficientNet_dataset.zip'  # 你的ZIP檔案路徑\n","zip_local = '/content/EfficientNet_dataset.zip'\n","\n","# 檢查是否已經解壓過\n","if not os.path.exists('/content/EfficientNet_dataset'):\n","    # 複製ZIP檔案\n","    shutil.copy2(zip_source, zip_local)\n","    print(\"✓ ZIP檔案複製完成\")\n","\n","    # 解壓縮到本地\n","    print(\"正在解壓縮資料集...\")\n","    with zipfile.ZipFile(zip_local, 'r') as zip_ref:\n","        zip_ref.extractall('/content/')\n","    print(\"✓ 資料集解壓縮完成\")\n","\n","    # 清理ZIP檔案以節省空間\n","    os.remove(zip_local)\n","    print(\"✓ 已清理臨時ZIP檔案\")\n","else:\n","    print(\"✓ 資料集已存在於本地\")\n","\n","# 設定本地資料集路徑\n","train_dir = '/content/EfficientNet_dataset/train'\n","val_dir = '/content/EfficientNet_dataset/valid'\n","test_dir = '/content/EfficientNet_dataset/test'\n","\n","# 驗證路徑是否正確\n","print(\"檢查本地資料集路徑:\")\n","for path, name in [(train_dir, '訓練'), (val_dir, '驗證'), (test_dir, '測試')]:\n","    if os.path.exists(path):\n","        print(f\"✓ {name}資料夾存在: {path}\")\n","    else:\n","        print(f\"✗ {name}資料夾不存在: {path}\")\n","\n","# 詳細檢查資料集結構\n","def analyze_dataset(data_dir, name):\n","    print(f\"\\n{name}資料集分析:\")\n","    print(\"=\"*50)\n","    if os.path.exists(data_dir):\n","        classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n","        total_images = 0\n","        class_distribution = {}\n","\n","        for cls in classes:\n","            cls_path = os.path.join(data_dir, cls)\n","            images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n","            count = len(images)\n","            class_distribution[cls] = count\n","            total_images += count\n","            print(f\"  {cls}: {count} 張圖片\")\n","\n","        print(f\"  總計: {total_images} 張圖片\")\n","        print(f\"  類別分布: {class_distribution}\")\n","\n","        # 計算類別平衡性\n","        if len(class_distribution) == 2:\n","            values = list(class_distribution.values())\n","            balance_ratio = min(values) / max(values) if max(values) > 0 else 0\n","            print(f\"  類別平衡比例: {balance_ratio:.3f}\")\n","\n","        return class_distribution, total_images\n","    else:\n","        print(f\"  資料夾不存在: {data_dir}\")\n","        return {}, 0\n","\n","# 分析所有資料集\n","train_dist, train_total = analyze_dataset(train_dir, \"訓練\")\n","val_dist, val_total = analyze_dataset(val_dir, \"驗證\")\n","test_dist, test_total = analyze_dataset(test_dir, \"測試\")\n","\n","# 記憶體優化設定\n","import torch\n","import gc\n","\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","# 修正後的資料前處理（減少過度增強）\n","train_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomRotation(degrees=10),  # 減少旋轉角度\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # 減少顏色變化\n","    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),  # 減少變形\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# 建立資料集\n","train_dataset = ImageFolder(train_dir, transform=train_transforms)\n","val_dataset = ImageFolder(val_dir, transform=val_transforms)\n","test_dataset = ImageFolder(test_dir, transform=val_transforms)\n","\n","# 建立資料載入器（適當調整批次大小）\n","batch_size = 24  # 適當增加批次大小\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","\n","print(f\"\\n最終資料集統計:\")\n","print(f\"訓練樣本數: {len(train_dataset)}\")\n","print(f\"驗證樣本數: {len(val_dataset)}\")\n","print(f\"測試樣本數: {len(test_dataset)}\")\n","print(f\"類別數: {len(train_dataset.classes)}\")\n","print(f\"類別名稱: {train_dataset.classes}\")\n","print(f\"批次大小: {batch_size}\")\n","\n","# 建立模型\n","def create_efficientnetv2_model(num_classes, model_name='tf_efficientnetv2_s.in1k'):\n","    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n","    return model\n","\n","def count_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    return total_params, trainable_params\n","\n","num_classes = len(train_dataset.classes)\n","model = create_efficientnetv2_model(num_classes, 'tf_efficientnetv2_s.in1k')\n","\n","# 模型分析\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","total_params, trainable_params = count_parameters(model)\n","print(f\"\\n模型架構分析:\")\n","print(f\"模型: EfficientNetV2-S\")\n","print(f\"使用設備: {device}\")\n","print(f\"總參數數量: {total_params:,}\")\n","print(f\"可訓練參數: {trainable_params:,}\")\n","print(f\"類別映射: {dict(enumerate(train_dataset.classes))}\")\n","\n","# 早停機制\n","class EarlyStopping:\n","    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.restore_best_weights = restore_best_weights\n","        self.counter = 0\n","        self.best_loss = float('inf')\n","        self.best_weights = None\n","\n","    def __call__(self, val_loss, model):\n","        if val_loss < self.best_loss - self.min_delta:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","            if self.restore_best_weights:\n","                self.best_weights = model.state_dict().copy()\n","        else:\n","            self.counter += 1\n","\n","        if self.counter >= self.patience and self.restore_best_weights:\n","            model.load_state_dict(self.best_weights)\n","\n","        return self.counter >= self.patience\n","\n","# 修正後的指標計算函數\n","def calculate_comprehensive_metrics(y_true, y_pred, y_prob=None):\n","    \"\"\"計算全面的分類指標\"\"\"\n","    metrics = {}\n","\n","    # 基本指標\n","    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n","    metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)\n","\n","    # 二分類特殊處理\n","    if len(np.unique(y_true)) == 2:\n","        # 假設類別0是異物(F)，類別1是非異物(Not_F)\n","        metrics['precision'] = precision_score(y_true, y_pred, pos_label=0, zero_division=0)\n","        metrics['recall'] = recall_score(y_true, y_pred, pos_label=0, zero_division=0)\n","        metrics['f1'] = f1_score(y_true, y_pred, pos_label=0, zero_division=0)\n","\n","        # 混淆矩陣元素\n","        cm = confusion_matrix(y_true, y_pred)\n","        if cm.shape == (2, 2):\n","            tn, fp, fn, tp = cm.ravel()\n","            metrics['true_negatives'] = tn\n","            metrics['false_positives'] = fp\n","            metrics['false_negatives'] = fn\n","            metrics['true_positives'] = tp\n","\n","            # 特異性和敏感性\n","            metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0\n","            metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0\n","\n","        # 其他指標\n","        metrics['matthews_corrcoef'] = matthews_corrcoef(y_true, y_pred)\n","        metrics['cohen_kappa'] = cohen_kappa_score(y_true, y_pred)\n","\n","        # 修正ROC-AUC和PR-AUC計算\n","        if y_prob is not None:\n","            y_prob_array = np.array(y_prob)\n","            if y_prob_array.ndim == 2 and y_prob_array.shape[1] == 2:\n","                try:\n","                    # 使用類別0（異物）的概率\n","                    fpr, tpr, _ = roc_curve(y_true, y_prob_array[:, 0], pos_label=0)\n","                    metrics['roc_auc'] = auc(fpr, tpr)\n","\n","                    # PR-AUC\n","                    precision_curve, recall_curve, _ = precision_recall_curve(\n","                        y_true, y_prob_array[:, 0], pos_label=0\n","                    )\n","                    metrics['pr_auc'] = auc(recall_curve, precision_curve)\n","                    metrics['average_precision'] = average_precision_score(\n","                        y_true, y_prob_array[:, 0], pos_label=0\n","                    )\n","                except:\n","                    metrics['roc_auc'] = 0\n","                    metrics['pr_auc'] = 0\n","                    metrics['average_precision'] = 0\n","    else:\n","        # 多分類\n","        metrics['precision'] = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","        metrics['recall'] = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","        metrics['f1'] = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","        metrics['matthews_corrcoef'] = matthews_corrcoef(y_true, y_pred)\n","        metrics['cohen_kappa'] = cohen_kappa_score(y_true, y_pred)\n","\n","    # 每個類別的指標\n","    try:\n","        metrics['precision_per_class'] = precision_score(y_true, y_pred, average=None, zero_division=0)\n","        metrics['recall_per_class'] = recall_score(y_true, y_pred, average=None, zero_division=0)\n","        metrics['f1_per_class'] = f1_score(y_true, y_pred, average=None, zero_division=0)\n","    except:\n","        metrics['precision_per_class'] = np.array([0])\n","        metrics['recall_per_class'] = np.array([0])\n","        metrics['f1_per_class'] = np.array([0])\n","\n","    return metrics\n","\n","# 修正後的訓練函數\n","def train_epoch(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","    all_probs = []\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","\n","        # 添加梯度裁剪\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        # 收集預測結果（避免梯度計算）\n","        with torch.no_grad():\n","            probs = torch.softmax(output, dim=1)\n","            _, predicted = torch.max(output, 1)\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(target.cpu().numpy())\n","            all_probs.extend(probs.cpu().numpy())\n","\n","        # 清理記憶體\n","        del data, target, output, loss\n","        if batch_idx % 10 == 0:\n","            torch.cuda.empty_cache()\n","\n","        if batch_idx % 20 == 0:\n","            print(f'  Batch {batch_idx}/{len(train_loader)}, Loss: {running_loss/(batch_idx+1):.4f}')\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    metrics = calculate_comprehensive_metrics(all_labels, all_preds, all_probs)\n","\n","    return epoch_loss, metrics, all_labels, all_preds, all_probs\n","\n","# 修正後的驗證函數\n","def validate_epoch(model, val_loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","    all_probs = []\n","    # 添加時間統計\n","    total_inference_time = 0.0\n","    total_samples = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(val_loader):\n","            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n","            # 測量推論時間\n","            start_time = time.time()\n","            output = model(data)\n","            inference_time = time.time() - start_time\n","\n","            total_inference_time += inference_time\n","            total_samples += data.size(0)\n","            loss = criterion(output, target)\n","\n","            running_loss += loss.item()\n","\n","            probs = torch.softmax(output, dim=1)\n","            _, predicted = torch.max(output, 1)\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(target.cpu().numpy())\n","            all_probs.extend(probs.cpu().numpy())\n","\n","            # 清理記憶體\n","            del data, target, output, loss\n","            if batch_idx % 10 == 0:\n","                torch.cuda.empty_cache()\n","\n","    epoch_loss = running_loss / len(val_loader)\n","    metrics = calculate_comprehensive_metrics(all_labels, all_preds, all_probs)\n","\n","    # 計算速度統計\n","    avg_inference_time = total_inference_time / len(val_loader)\n","    fps = total_samples / total_inference_time\n","    ms_per_image = (total_inference_time / total_samples) * 1000\n","\n","    speed_stats = {\n","        'total_inference_time': total_inference_time,\n","        'avg_batch_time': avg_inference_time,\n","        'fps': fps,\n","        'ms_per_image': ms_per_image,\n","        'total_samples': total_samples\n","    }\n","\n","\n","    return epoch_loss, metrics, all_labels, all_preds, all_probs, speed_stats\n","\n","# 修正後的繪圖函數\n","def plot_roc_pr_curves_multiclass(test_labels, test_probs, class_names, save_path):\n","    \"\"\"多分類ROC和PR曲線\"\"\"\n","    plt.figure(figsize=(15, 6))\n","\n","    test_probs_array = np.array(test_probs)\n","    n_classes = len(class_names)\n","\n","    # 為每個類別計算ROC曲線\n","    plt.subplot(1, 2, 1)\n","    for i in range(n_classes):\n","        # 將多分類問題轉為一對多的二分類\n","        y_binary = (np.array(test_labels) == i).astype(int)\n","        if test_probs_array.ndim == 2 and test_probs_array.shape[1] == n_classes:\n","            fpr, tpr, _ = roc_curve(y_binary, test_probs_array[:, i])\n","            roc_auc = auc(fpr, tpr)\n","            plt.plot(fpr, tpr, linewidth=2,\n","                    label=f'{class_names[i]} (AUC = {roc_auc:.3f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Multi-class ROC Curves')\n","    plt.legend()\n","    plt.grid(True, alpha=0.3)\n","\n","    # 為每個類別計算PR曲線\n","    plt.subplot(1, 2, 2)\n","    for i in range(n_classes):\n","        y_binary = (np.array(test_labels) == i).astype(int)\n","        if test_probs_array.ndim == 2 and test_probs_array.shape[1] == n_classes:\n","            precision_curve, recall_curve, _ = precision_recall_curve(\n","                y_binary, test_probs_array[:, i]\n","            )\n","            avg_precision = average_precision_score(y_binary, test_probs_array[:, i])\n","            plt.plot(recall_curve, precision_curve, linewidth=2,\n","                    label=f'{class_names[i]} (AP = {avg_precision:.3f})')\n","\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Multi-class Precision-Recall Curves')\n","    plt.legend()\n","    plt.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","\n","# 修正後的混淆矩陣繪圖\n","def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","\n","    # 計算百分比\n","    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n","\n","    # 創建標籤\n","    labels = []\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            labels.append(f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)')\n","\n","    labels = np.asarray(labels).reshape(cm.shape)\n","\n","    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues',\n","                xticklabels=class_names, yticklabels=class_names)\n","    plt.title('Confusion Matrix')\n","    plt.ylabel('True Label')\n","    plt.xlabel('Predicted Label')\n","    plt.tight_layout()\n","    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","# 模型保存函數\n","def save_model(model, optimizer, scheduler, epoch, best_metrics, save_path):\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'scheduler_state_dict': scheduler.state_dict(),\n","        'best_metrics': best_metrics,\n","        'model_architecture': 'tf_efficientnetv2_s.in1k',\n","        'num_classes': len(train_dataset.classes),\n","        'class_names': train_dataset.classes,\n","        'input_size': (224, 224),\n","        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","    }, save_path)\n","\n","# 訓練設置\n","# 計算類別權重\n","class_weights = compute_class_weight(\n","    'balanced',\n","    classes=np.unique(train_dataset.targets),\n","    y=train_dataset.targets\n",")\n","class_weights = torch.FloatTensor(class_weights).to(device)\n","print(f\"類別權重: {dict(zip(train_dataset.classes, class_weights.cpu().numpy()))}\")\n","\n","# 使用加權損失函數\n","criterion = nn.CrossEntropyLoss(weight=class_weights)\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n","\n","# 修正後的學習率調度器\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",")\n","\n","# 早停機制\n","early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n","\n","# 訓練參數\n","num_epochs = 30\n","best_val_acc = 0.0\n","best_val_f1 = 0.0\n","best_model_path = '/tmp/best_model.pth'\n","\n","# 詳細指標記錄\n","training_history = {\n","    'train_loss': [], 'val_loss': [],\n","    'train_acc': [], 'val_acc': [],\n","    'train_balanced_acc': [], 'val_balanced_acc': [],\n","    'train_precision': [], 'val_precision': [],\n","    'train_recall': [], 'val_recall': [],\n","    'train_f1': [], 'val_f1': [],\n","    'train_specificity': [], 'val_specificity': [],\n","    'train_sensitivity': [], 'val_sensitivity': [],\n","    'train_matthews': [], 'val_matthews': [],\n","    'train_kappa': [], 'val_kappa': [],\n","    'train_roc_auc': [], 'val_roc_auc': [],\n","    'train_pr_auc': [], 'val_pr_auc': [],\n","    'learning_rate': [],\n","    'epoch_times': []\n","}\n","\n","print(\"開始訓練異物檢測模型...\")\n","print(\"=\"*70)\n","start_time = time.time()\n","\n","# 修正後的訓練循環\n","for epoch in range(num_epochs):\n","    epoch_start_time = time.time()\n","    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n","    print('-' * 70)\n","\n","    # 訓練\n","    train_loss, train_metrics, train_labels, train_preds, train_probs = train_epoch(\n","        model, train_loader, criterion, optimizer, device)\n","\n","    # 驗證階段\n","    val_loss, val_metrics, val_labels, val_preds, val_probs, val_speed = validate_epoch(\n","    model, val_loader, criterion, device)\n","\n","    # 更新學習率\n","    current_lr = optimizer.param_groups[0]['lr']\n","    scheduler.step(val_loss)\n","\n","    epoch_time = time.time() - epoch_start_time\n","\n","    # 記錄所有指標\n","    training_history['train_loss'].append(train_loss)\n","    training_history['val_loss'].append(val_loss)\n","    training_history['train_acc'].append(train_metrics['accuracy'])\n","    training_history['val_acc'].append(val_metrics['accuracy'])\n","    training_history['train_balanced_acc'].append(train_metrics['balanced_accuracy'])\n","    training_history['val_balanced_acc'].append(val_metrics['balanced_accuracy'])\n","    training_history['train_precision'].append(train_metrics['precision'])\n","    training_history['val_precision'].append(val_metrics['precision'])\n","    training_history['train_recall'].append(train_metrics['recall'])\n","    training_history['val_recall'].append(val_metrics['recall'])\n","    training_history['train_f1'].append(train_metrics['f1'])\n","    training_history['val_f1'].append(val_metrics['f1'])\n","    training_history['train_specificity'].append(train_metrics.get('specificity', 0))\n","    training_history['val_specificity'].append(val_metrics.get('specificity', 0))\n","    training_history['train_sensitivity'].append(train_metrics.get('sensitivity', 0))\n","    training_history['val_sensitivity'].append(val_metrics.get('sensitivity', 0))\n","    training_history['train_matthews'].append(train_metrics['matthews_corrcoef'])\n","    training_history['val_matthews'].append(val_metrics['matthews_corrcoef'])\n","    training_history['train_kappa'].append(train_metrics['cohen_kappa'])\n","    training_history['val_kappa'].append(val_metrics['cohen_kappa'])\n","    training_history['train_roc_auc'].append(train_metrics.get('roc_auc', 0))\n","    training_history['val_roc_auc'].append(val_metrics.get('roc_auc', 0))\n","    training_history['train_pr_auc'].append(train_metrics.get('pr_auc', 0))\n","    training_history['val_pr_auc'].append(val_metrics.get('pr_auc', 0))\n","    training_history['learning_rate'].append(current_lr)\n","    training_history['epoch_times'].append(epoch_time)\n","\n","    # 詳細顯示結果\n","    print(f'訓練指標:')\n","    print(f'  Loss: {train_loss:.4f}, Acc: {train_metrics[\"accuracy\"]:.4f}, F1: {train_metrics[\"f1\"]:.4f}')\n","    print(f'  Precision: {train_metrics[\"precision\"]:.4f}, Recall: {train_metrics[\"recall\"]:.4f}')\n","    print(f'  ROC-AUC: {train_metrics.get(\"roc_auc\", 0):.4f}')\n","\n","    print(f'驗證指標:')\n","    print(f'  Loss: {val_loss:.4f}, Acc: {val_metrics[\"accuracy\"]:.4f}, F1: {val_metrics[\"f1\"]:.4f}')\n","    print(f'  Precision: {val_metrics[\"precision\"]:.4f}, Recall: {val_metrics[\"recall\"]:.4f}')\n","    print(f'  ROC-AUC: {val_metrics.get(\"roc_auc\", 0):.4f}')\n","\n","    print(f'學習率: {current_lr:.6f}, 時間: {epoch_time:.2f}秒')\n","\n","    # 保存最佳模型（基於F1分數）\n","    if val_metrics['f1'] > best_val_f1:\n","        best_val_f1 = val_metrics['f1']\n","        best_val_acc = val_metrics['accuracy']\n","        save_model(model, optimizer, scheduler, epoch,\n","                  {'f1': best_val_f1, 'accuracy': best_val_acc},\n","                  best_model_path)\n","        print(f'★ 新的最佳模型! F1: {val_metrics[\"f1\"]:.4f}, Acc: {val_metrics[\"accuracy\"]:.4f}')\n","\n","    # 早停檢查\n","    if early_stopping(val_loss, model):\n","        print(f\"Early stopping triggered at epoch {epoch+1}\")\n","        break\n","\n","    # 清理記憶體\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","total_time = time.time() - start_time\n","print(f'\\n訓練完成! 總時間: {total_time/60:.2f} 分鐘')\n","print(f'最佳驗證F1分數: {best_val_f1:.4f}')\n","print(f'最佳驗證準確率: {best_val_acc:.4f}')\n","\n","# 載入最佳模型進行測試\n","if os.path.exists(best_model_path):\n","    checkpoint = torch.load(best_model_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    print(\"已載入最佳模型進行測試\")\n","\n","# 測試集評估\n","print(\"\\n進行測試集評估...\")\n","# 測試階段\n","test_loss, test_metrics, test_labels, test_preds, test_probs, test_speed = validate_epoch(\n","    model, test_loader, criterion, device)\n","\n","print(f\"\\n測試集最終結果:\")\n","print(\"=\"*50)\n","print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n","print(f\"Balanced Accuracy: {test_metrics['balanced_accuracy']:.4f}\")\n","print(f\"Precision: {test_metrics['precision']:.4f}\")\n","print(f\"Recall: {test_metrics['recall']:.4f}\")\n","print(f\"F1-Score: {test_metrics['f1']:.4f}\")\n","print(f\"Specificity: {test_metrics.get('specificity', 0):.4f}\")\n","print(f\"Sensitivity: {test_metrics.get('sensitivity', 0):.4f}\")\n","\n","\n","# 添加速度統計\n","print(f\"\\n推論速度統計:\")\n","print(f\"平均FPS: {test_speed['fps']:.2f}\")\n","print(f\"每張圖片推論時間: {test_speed['ms_per_image']:.2f} ms\")\n","print(f\"總推論時間: {test_speed['total_inference_time']:.4f} 秒\")\n","print(f\"總測試樣本數: {test_speed['total_samples']}\")"]},{"cell_type":"markdown","source":["打包"],"metadata":{"id":"P5aTBkp5ir_M"}},{"cell_type":"code","source":["# 模型打包與保存程式\n","import os\n","import json\n","import zipfile\n","import shutil\n","from datetime import datetime\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# 創建結果目錄\n","results_dir = '/content/efficientnet_results'\n","os.makedirs(results_dir, exist_ok=True)\n","\n","# 1. 保存訓練歷史為JSON和CSV\n","print(\"正在保存訓練歷史...\")\n","history_json_path = os.path.join(results_dir, 'training_history.json')\n","history_csv_path = os.path.join(results_dir, 'training_history.csv')\n","\n","# 保存為JSON\n","with open(history_json_path, 'w', encoding='utf-8') as f:\n","    json.dump(training_history, f, ensure_ascii=False, indent=2, default=str)\n","\n","# 保存為CSV\n","df_history = pd.DataFrame(training_history)\n","df_history.to_csv(history_csv_path, index=False, encoding='utf-8')\n","\n","# 2. 保存最終測試結果\n","print(\"正在保存測試結果...\")\n","test_results = {\n","    'model_info': {\n","        'model_name': 'EfficientNetV2-S',\n","        'architecture': 'tf_efficientnetv2_s.in1k',\n","        'num_classes': len(train_dataset.classes),\n","        'class_names': train_dataset.classes,\n","        'input_size': [224, 224],\n","        'batch_size': batch_size,\n","        'total_epochs': len(training_history['train_loss']),\n","        'best_epoch': np.argmax(training_history['val_f1']) + 1,\n","        'training_time_minutes': total_time/60,\n","        'total_parameters': total_params,\n","        'trainable_parameters': trainable_params\n","    },\n","    'dataset_info': {\n","        'train_samples': len(train_dataset),\n","        'val_samples': len(val_dataset),\n","        'test_samples': len(test_dataset),\n","        'train_distribution': train_dist,\n","        'val_distribution': val_dist,\n","        'test_distribution': test_dist\n","    },\n","    'final_test_metrics': {\n","        'accuracy': float(test_metrics['accuracy']),\n","        'balanced_accuracy': float(test_metrics['balanced_accuracy']),\n","        'precision': float(test_metrics['precision']),\n","        'recall': float(test_metrics['recall']),\n","        'f1_score': float(test_metrics['f1']),\n","        'specificity': float(test_metrics.get('specificity', 0)),\n","        'sensitivity': float(test_metrics.get('sensitivity', 0)),\n","        'matthews_corrcoef': float(test_metrics['matthews_corrcoef']),\n","        'cohen_kappa': float(test_metrics['cohen_kappa']),\n","        'roc_auc': float(test_metrics.get('roc_auc', 0)),\n","        'pr_auc': float(test_metrics.get('pr_auc', 0)),\n","        'test_loss': float(test_loss)\n","    },\n","    'speed_statistics': {\n","    'fps': float(test_speed['fps']),\n","    'ms_per_image': float(test_speed['ms_per_image']),\n","    'total_inference_time': float(test_speed['total_inference_time']),\n","    'avg_batch_time': float(test_speed['avg_batch_time']),\n","    'total_samples': int(test_speed['total_samples'])\n","    },\n","    'confusion_matrix': {\n","        'matrix': confusion_matrix(test_labels, test_preds).tolist(),\n","        'true_labels': test_labels,\n","        'predicted_labels': test_preds\n","    },\n","    'per_class_metrics': {\n","        'precision': test_metrics['precision_per_class'].tolist(),\n","        'recall': test_metrics['recall_per_class'].tolist(),\n","        'f1': test_metrics['f1_per_class'].tolist()\n","    },\n","    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","}\n","\n","test_results_path = os.path.join(results_dir, 'test_results.json')\n","with open(test_results_path, 'w', encoding='utf-8') as f:\n","    json.dump(test_results, f, ensure_ascii=False, indent=2, default=str)\n","\n","# 3. 創建詳細的分類報告\n","print(\"正在生成分類報告...\")\n","from sklearn.metrics import classification_report\n","class_report = classification_report(test_labels, test_preds,\n","                                   target_names=train_dataset.classes,\n","                                   output_dict=True)\n","class_report_path = os.path.join(results_dir, 'classification_report.json')\n","with open(class_report_path, 'w', encoding='utf-8') as f:\n","    json.dump(class_report, f, ensure_ascii=False, indent=2, default=str)\n","\n","# 4. 生成訓練過程視覺化圖表\n","print(\"正在生成視覺化圖表...\")\n","\n","# 訓練過程曲線\n","plt.figure(figsize=(20, 12))\n","\n","# 損失曲線\n","plt.subplot(3, 4, 1)\n","plt.plot(training_history['train_loss'], label='Training Loss')\n","plt.plot(training_history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# 準確率曲線\n","plt.subplot(3, 4, 2)\n","plt.plot(training_history['train_acc'], label='Training Accuracy')\n","plt.plot(training_history['val_acc'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# F1分數曲線\n","plt.subplot(3, 4, 3)\n","plt.plot(training_history['train_f1'], label='Training F1')\n","plt.plot(training_history['val_f1'], label='Validation F1')\n","plt.title('Training and Validation F1-Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('F1-Score')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# 精確度曲線\n","plt.subplot(3, 4, 4)\n","plt.plot(training_history['train_precision'], label='Training Precision')\n","plt.plot(training_history['val_precision'], label='Validation Precision')\n","plt.title('Training and Validation Precision')\n","plt.xlabel('Epoch')\n","plt.ylabel('Precision')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# 召回率曲線\n","plt.subplot(3, 4, 5)\n","plt.plot(training_history['train_recall'], label='Training Recall')\n","plt.plot(training_history['val_recall'], label='Validation Recall')\n","plt.title('Training and Validation Recall')\n","plt.xlabel('Epoch')\n","plt.ylabel('Recall')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# 平衡準確率曲線\n","plt.subplot(3, 4, 6)\n","plt.plot(training_history['train_balanced_acc'], label='Training Balanced Acc')\n","plt.plot(training_history['val_balanced_acc'], label='Validation Balanced Acc')\n","plt.title('Training and Validation Balanced Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Balanced Accuracy')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# ROC-AUC曲線\n","plt.subplot(3, 4, 7)\n","plt.plot(training_history['train_roc_auc'], label='Training ROC-AUC')\n","plt.plot(training_history['val_roc_auc'], label='Validation ROC-AUC')\n","plt.title('Training and Validation ROC-AUC')\n","plt.xlabel('Epoch')\n","plt.ylabel('ROC-AUC')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# Matthews相關係數曲線\n","plt.subplot(3, 4, 8)\n","plt.plot(training_history['train_matthews'], label='Training Matthews')\n","plt.plot(training_history['val_matthews'], label='Validation Matthews')\n","plt.title('Training and Validation Matthews Correlation')\n","plt.xlabel('Epoch')\n","plt.ylabel('Matthews Correlation')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# 學習率曲線\n","plt.subplot(3, 4, 9)\n","plt.plot(training_history['learning_rate'], label='Learning Rate')\n","plt.title('Learning Rate Schedule')\n","plt.xlabel('Epoch')\n","plt.ylabel('Learning Rate')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","plt.yscale('log')\n","\n","# 每個epoch的時間\n","plt.subplot(3, 4, 10)\n","plt.plot(training_history['epoch_times'], label='Epoch Time')\n","plt.title('Training Time per Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Time (seconds)')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# 特異性和敏感性\n","plt.subplot(3, 4, 11)\n","plt.plot(training_history['train_specificity'], label='Training Specificity')\n","plt.plot(training_history['val_specificity'], label='Validation Specificity')\n","plt.plot(training_history['train_sensitivity'], label='Training Sensitivity')\n","plt.plot(training_history['val_sensitivity'], label='Validation Sensitivity')\n","plt.title('Specificity and Sensitivity')\n","plt.xlabel('Epoch')\n","plt.ylabel('Score')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","# Cohen's Kappa\n","plt.subplot(3, 4, 12)\n","plt.plot(training_history['train_kappa'], label='Training Kappa')\n","plt.plot(training_history['val_kappa'], label='Validation Kappa')\n","plt.title('Cohen\\'s Kappa Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('Kappa')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","training_curves_path = os.path.join(results_dir, 'training_curves.png')\n","plt.savefig(training_curves_path, dpi=300, bbox_inches='tight')\n","plt.close()\n","\n","# 5. 生成混淆矩陣圖\n","confusion_matrix_path = os.path.join(results_dir, 'confusion_matrix.png')\n","plot_confusion_matrix(test_labels, test_preds, train_dataset.classes, confusion_matrix_path)\n","\n","# 6. 生成ROC和PR曲線\n","roc_pr_curves_path = os.path.join(results_dir, 'roc_pr_curves.png')\n","plot_roc_pr_curves_multiclass(test_labels, test_probs, train_dataset.classes, roc_pr_curves_path)\n","\n","\n","# 7. 生成每類別性能柱狀圖\n","plt.figure(figsize=(15, 10))\n","\n","# 每類別精確度\n","plt.subplot(2, 2, 1)\n","plt.bar(train_dataset.classes, test_metrics['precision_per_class'])\n","plt.title('Precision per Class')\n","plt.ylabel('Precision')\n","plt.xticks(rotation=45)\n","plt.grid(True, alpha=0.3)\n","\n","# 每類別召回率\n","plt.subplot(2, 2, 2)\n","plt.bar(train_dataset.classes, test_metrics['recall_per_class'])\n","plt.title('Recall per Class')\n","plt.ylabel('Recall')\n","plt.xticks(rotation=45)\n","plt.grid(True, alpha=0.3)\n","\n","# 每類別F1分數\n","plt.subplot(2, 2, 3)\n","plt.bar(train_dataset.classes, test_metrics['f1_per_class'])\n","plt.title('F1-Score per Class')\n","plt.ylabel('F1-Score')\n","plt.xticks(rotation=45)\n","plt.grid(True, alpha=0.3)\n","\n","# 數據分布\n","plt.subplot(2, 2, 4)\n","class_counts = [train_dist.get(cls, 0) for cls in train_dataset.classes]\n","plt.bar(train_dataset.classes, class_counts)\n","plt.title('Training Data Distribution')\n","plt.ylabel('Number of Samples')\n","plt.xticks(rotation=45)\n","plt.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","per_class_metrics_path = os.path.join(results_dir, 'per_class_metrics.png')\n","plt.savefig(per_class_metrics_path, dpi=300, bbox_inches='tight')\n","plt.close()\n","\n","# 8. 複製最佳模型到結果目錄\n","final_model_path = os.path.join(results_dir, 'best_model.pth')\n","if os.path.exists(best_model_path):\n","    shutil.copy2(best_model_path, final_model_path)\n","    print(\"✓ 最佳模型已複製\")\n","\n","# 9. 生成README文件\n","readme_content = f\"\"\"# EfficientNetV2-S 異物檢測模型訓練結果\n","\n","## 模型資訊\n","- **模型架構**: EfficientNetV2-S (tf_efficientnetv2_s.in1k)\n","- **類別數**: {len(train_dataset.classes)}\n","- **類別名稱**: {', '.join(train_dataset.classes)}\n","- **輸入尺寸**: 224x224\n","- **總參數數**: {total_params:,}\n","- **可訓練參數**: {trainable_params:,}\n","\n","## 資料集資訊\n","- **訓練樣本數**: {len(train_dataset)}\n","- **驗證樣本數**: {len(val_dataset)}\n","- **測試樣本數**: {len(test_dataset)}\n","\n","## 訓練設定\n","- **批次大小**: {batch_size}\n","- **總訓練時間**: {total_time/60:.2f} 分鐘\n","- **最佳epoch**: {np.argmax(training_history['val_f1']) + 1}\n","- **優化器**: AdamW\n","- **學習率調度**: ReduceLROnPlateau\n","- **早停機制**: 啟用 (patience=10)\n","\n","## 最終測試結果\n","- **準確率**: {test_metrics['accuracy']:.4f}\n","- **平衡準確率**: {test_metrics['balanced_accuracy']:.4f}\n","- **精確度**: {test_metrics['precision']:.4f}\n","- **召回率**: {test_metrics['recall']:.4f}\n","- **F1分數**: {test_metrics['f1']:.4f}\n","- **特異性**: {test_metrics.get('specificity', 0):.4f}\n","- **敏感性**: {test_metrics.get('sensitivity', 0):.4f}\n","- **Matthews相關係數**: {test_metrics['matthews_corrcoef']:.4f}\n","- **Cohen's Kappa**: {test_metrics['cohen_kappa']:.4f}\n","- **ROC-AUC**: {test_metrics.get('roc_auc', 0):.4f}\n","- **PR-AUC**: {test_metrics.get('pr_auc', 0):.4f}\n","## 推論速度\n","- **平均FPS**: {test_speed['fps']:.2f}\n","- **每張圖片推論時間**: {test_speed['ms_per_image']:.2f} ms\n","- **總推論時間**: {test_speed['total_inference_time']:.4f} 秒\n","\n","## 檔案說明\n","- `best_model.pth`: 最佳模型權重檔案\n","- `training_history.json`: 完整訓練歷史 (JSON格式)\n","- `training_history.csv`: 完整訓練歷史 (CSV格式)\n","- `test_results.json`: 詳細測試結果\n","- `classification_report.json`: 分類報告\n","- `training_curves.png`: 訓練過程曲線圖\n","- `confusion_matrix.png`: 混淆矩陣圖\n","- `roc_pr_curves.png`: ROC和PR曲線圖\n","- `per_class_metrics.png`: 每類別性能圖表\n","\n","## 使用方法\n","```python\n","import torch\n","import timm\n","\n","# 載入模型\n","checkpoint = torch.load('best_model.pth')\n","model = timm.create_model('tf_efficientnetv2_s.in1k', pretrained=False, num_classes={len(train_dataset.classes)})\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.eval()\n","\n","# 進行推論\n","# ... (預處理圖像)\n","# output = model(input_tensor)\n","```\n","\n","生成時間: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n","\"\"\"\n","\n","readme_path = os.path.join(results_dir, 'README.md')\n","with open(readme_path, 'w', encoding='utf-8') as f:\n","    f.write(readme_content)\n","\n","# 10. 創建ZIP檔案\n","print(\"正在創建ZIP檔案...\")\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","# 定義 ZIP 檔案的目標目錄路徑\n","zip_output_dir = os.path.join('/content/', 'efficientnetV2')\n","# 確保目標目錄存在，如果不存在則創建\n","os.makedirs(zip_output_dir, exist_ok=True)\n","\n","# 組合完整的 ZIP 檔名和路徑\n","zip_filename = f'EfficientNetV2_ForeignObject_Detection_{timestamp}.zip'\n","zip_path = os.path.join(zip_output_dir, zip_filename)\n","\n","with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","    for root, dirs, files in os.walk(results_dir):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            arc_name = os.path.relpath(file_path, results_dir)\n","            zipf.write(file_path, arc_name)\n","            print(f\"  已添加: {arc_name}\")\n","\n","print(f\"✓ ZIP檔案已創建: {zip_path}\")\n","print(f\"檔案大小: {os.path.getsize(zip_path) / (1024*1024):.2f} MB\")\n","\n","# 11. 上傳到Google Drive\n","print(\"正在上傳到Google Drive...\")\n","drive_save_path = f'/content/drive/My Drive/DualStage-DefectAI/輸出/EfficientNetv2s輸出/{zip_filename}'\n","\n","try:\n","    shutil.copy2(zip_path, drive_save_path)\n","    print(f\"✓ 檔案已成功上傳到Google Drive: {drive_save_path}\")\n","except Exception as e:\n","    print(f\"✗ 上傳失敗: {e}\")\n","    print(\"請手動將檔案複製到Google Drive\")\n","\n","# 12. 顯示檔案清單\n","print(f\"\\n檔案清單:\")\n","print(\"=\"*50)\n","for root, dirs, files in os.walk(results_dir):\n","    for file in files:\n","        file_path = os.path.join(root, file)\n","        file_size = os.path.getsize(file_path)\n","        print(f\"{file:<30} {file_size:>10} bytes\")\n","\n","print(f\"\\n所有檔案已打包完成！\")\n","print(f\"ZIP檔案位置: {zip_path}\")\n","print(f\"Google Drive位置: {drive_save_path}\")\n","print(f\"結果目錄: {results_dir}\")\n","\n","# 13. 清理臨時檔案\n","print(\"\\n正在清理臨時檔案...\")\n","if os.path.exists(best_model_path):\n","    os.remove(best_model_path)\n","    print(\"✓ 臨時模型檔案已清理\")\n","\n","print(\"✓ 所有操作完成！\")"],"metadata":{"id":"OW8GWaiRioAt","executionInfo":{"status":"ok","timestamp":1753430402933,"user_tz":-480,"elapsed":31837,"user":{"displayName":"李柏駿","userId":"07522532513227506161"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"656817ca-b5f4-4e94-8d21-f4a56d76a359"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["正在保存訓練歷史...\n","正在保存測試結果...\n","正在生成分類報告...\n","正在生成視覺化圖表...\n","✓ 最佳模型已複製\n","正在創建ZIP檔案...\n","  已添加: README.md\n","  已添加: per_class_metrics.png\n","  已添加: training_history.json\n","  已添加: test_results.json\n","  已添加: training_curves.png\n","  已添加: training_history.csv\n","  已添加: roc_pr_curves.png\n","  已添加: classification_report.json\n","  已添加: confusion_matrix.png\n","  已添加: best_model.pth\n","✓ ZIP檔案已創建: /content/efficientnetV2/EfficientNetV2_ForeignObject_Detection_20250725_075942.zip\n","檔案大小: 217.19 MB\n","正在上傳到Google Drive...\n","✓ 檔案已成功上傳到Google Drive: /content/drive/My Drive/暑評yolotla/EfficientNetV2_ForeignObject_Detection_20250725_075942.zip\n","\n","檔案清單:\n","==================================================\n","README.md                            1812 bytes\n","per_class_metrics.png              183236 bytes\n","training_history.json               12044 bytes\n","test_results.json                  104570 bytes\n","training_curves.png               1096480 bytes\n","training_history.csv                 8636 bytes\n","roc_pr_curves.png                  177441 bytes\n","classification_report.json            695 bytes\n","confusion_matrix.png               126244 bytes\n","best_model.pth                  243458378 bytes\n","\n","所有檔案已打包完成！\n","ZIP檔案位置: /content/efficientnetV2/EfficientNetV2_ForeignObject_Detection_20250725_075942.zip\n","Google Drive位置: /content/drive/My Drive/暑評yolotla/EfficientNetV2_ForeignObject_Detection_20250725_075942.zip\n","結果目錄: /content/efficientnet_results\n","\n","正在清理臨時檔案...\n","✓ 臨時模型檔案已清理\n","✓ 所有操作完成！\n"]}]}]}