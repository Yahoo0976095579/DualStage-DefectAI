{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM2EbjhEqC+gexHjV6hFeRp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EpALH6CFbeIR2G4tJEphjG3MgzV4oIwy"},"id":"T1NVCMmBA_YL","executionInfo":{"status":"ok","timestamp":1753438023827,"user_tz":-480,"elapsed":120469,"user":{"displayName":"ææŸé§¿","userId":"07522532513227506161"}},"outputId":"87856d19-9e85-48a4-c9fd-d66e0ea5a20c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# ==============================================================================\n","# YOLOv5s + EfficientNetV2s é›™éšæ®µè¾¨è­˜æµç¨‹ï¼ˆF/S/Vä¸‰åˆ†é¡ï¼‹æ¨è«–é€Ÿåº¦ï¼‹è‡ªå‹•æ‰“åŒ…ï¼‰\n","# ==============================================================================\n","\n","import os\n","import shutil\n","import time\n","from datetime import datetime\n","from google.colab import drive\n","import torch\n","import timm\n","import cv2\n","import pandas as pd\n","import numpy as np\n","from PIL import Image, ImageDraw, ImageFont\n","import torchvision.transforms as transforms\n","from IPython.display import display as ipy_display\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# 1. æ›è¼‰ Google Drive\n","drive.mount('/content/drive')\n","\n","# ====== å…‹éš† YOLOv5 ç¨‹å¼åº« ======\n","if not os.path.exists('/content/yolov5'):\n","    !git clone https://github.com/ultralytics/yolov5.git /content/yolov5\n","    %cd /content/yolov5\n","    !pip install -r requirements.txt\n","    %cd /content\n","\n","# 2. ä½¿ç”¨è€…è¨­å®šå€\n","YOLO_MODEL_PATH = '/content/drive/MyDrive/DualStage-DefectAI/ç¨‹å¼/yolo+effæ¨¡å‹èˆ‡æ¸¬è©¦é›†/yolo_best.pt'\n","EFFICIENTNET_MODEL_PATH = '/content/drive/MyDrive/DualStage-DefectAI/ç¨‹å¼/yolo+effæ¨¡å‹èˆ‡æ¸¬è©¦é›†/eff_best.pth'\n","TEST_IMAGES_DIR = '/content/drive/MyDrive/DualStage-DefectAI/ç¨‹å¼/yolo+effæ¨¡å‹èˆ‡æ¸¬è©¦é›†/æ¸¬è©¦é›†/images'\n","OUTPUT_DIR_ON_DRIVE = '/content/drive/MyDrive/DualStage-DefectAI/è¼¸å‡º/yolo+efficientnet'\n","YOLO_CONF_THRESHOLD = 0.2\n","CROP_PADDING_RATIO = 0.1\n","\n","# 3. æª¢æŸ¥è·¯å¾‘\n","paths_to_check = {\n","    \"YOLO æ¨¡å‹\": YOLO_MODEL_PATH,\n","    \"EfficientNetV2 æ¨¡å‹\": EFFICIENTNET_MODEL_PATH,\n","    \"æ¸¬è©¦åœ–ç‰‡è³‡æ–™å¤¾\": TEST_IMAGES_DIR,\n","}\n","all_paths_ok = True\n","for name, path in paths_to_check.items():\n","    if not os.path.exists(path):\n","        print(f\"âœ— éŒ¯èª¤: æ‰¾ä¸åˆ° {name} -> {path}\")\n","        all_paths_ok = False\n","if not all_paths_ok:\n","    raise FileNotFoundError(\"æœ‰è·¯å¾‘è¨­å®šéŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹è¨Šæ¯ï¼\")\n","\n","# 4. è¼‰å…¥æ¨¡å‹\n","@torch.no_grad()\n","def load_models():\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    yolo_model = torch.hub.load('/content/yolov5', 'custom', path=YOLO_MODEL_PATH, source='local')\n","    yolo_model.conf = YOLO_CONF_THRESHOLD\n","    yolo_model.to(device)\n","    yolo_model.eval()\n","    # æ­¤è™•å°‡class_namesæ”¹ç‚ºä¸‰é¡\n","    checkpoint = torch.load(EFFICIENTNET_MODEL_PATH, map_location=device)\n","    effnet_class_names = checkpoint.get('class_names', ['F', 'S', 'V'])\n","    num_classes = len(effnet_class_names)\n","    effnet_model = timm.create_model('tf_efficientnetv2_s.in1k', pretrained=False, num_classes=num_classes)\n","    effnet_model.load_state_dict(checkpoint['model_state_dict'])\n","    effnet_model.to(device)\n","    effnet_model.eval()\n","    return yolo_model, effnet_model, effnet_class_names, device\n","\n","def get_efficientnet_transforms():\n","    return transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","def draw_on_image(image, detections_df):\n","    img_draw = image.copy()\n","    draw = ImageDraw.Draw(img_draw)\n","    try:\n","        font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", 20)\n","    except IOError:\n","        font = ImageFont.load_default()\n","\n","    for _, row in detections_df.iterrows():\n","        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n","        # åˆ¤æ–·éšæ®µ\n","        if 'effnet_class' in row:\n","            effnet_class = row.get('effnet_class', '')\n","            # === ä¸‰åˆ†é¡é¡è‰²æ¨™ç¤ºï¼šç´…F è—S æ©˜V ===\n","            if effnet_class == 'F':\n","                color = 'red'\n","            elif effnet_class == 'S':\n","                color = 'blue'\n","            elif effnet_class == 'V':\n","                color = 'orange'\n","            else:\n","                color = 'gray'\n","            confidence = row.get('effnet_confidence', 0)\n","            label = f\"{effnet_class}: {confidence:.2%}\"\n","        else:\n","            yolo_class = row['name']\n","            color = 'red' if row['name'] == 'F' else 'blue'\n","            confidence = row.get('confidence', 0)\n","            label = f\"{yolo_class}: {confidence:.2%}\"\n","\n","        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n","        try:\n","            text_bbox = draw.textbbox((0, 0), label, font=font)\n","            text_w = text_bbox[2] - text_bbox[0]\n","            text_h = text_bbox[3] - text_bbox[1]\n","            text_y_pos = y1 - text_h - 10\n","            if text_y_pos < 0: text_y_pos = y1 + 5\n","            draw.rectangle([x1, text_y_pos, x1 + text_w + 10, text_y_pos + text_h + 5], fill=color)\n","            draw.text((x1 + 5, text_y_pos), label, fill='white', font=font)\n","        except AttributeError:\n","            draw.text((x1 + 5, y1 - 20), label, fill=color, font=font)\n","    return img_draw\n","\n","# 5. å–®å¼µåœ–ç‰‡è™•ç†ï¼ˆåŒæ™‚å›å‚³æ¨è«–æ™‚é–“ï¼‰\n","@torch.no_grad()\n","def process_image(image_path, yolo_model, effnet_model, effnet_transforms, effnet_class_names, device):\n","    try:\n","        original_image = Image.open(image_path).convert('RGB')\n","    except Exception as e:\n","        print(f\"âœ— ç„¡æ³•è®€å–åœ–ç‰‡ {os.path.basename(image_path)}: {e}\")\n","        return None, pd.DataFrame(), pd.DataFrame(), 0, 0\n","    img_w, img_h = original_image.size\n","    # YOLOv5s ç‰©ä»¶åµæ¸¬\n","    t0 = time.time()\n","    yolo_results = yolo_model(original_image)\n","    t1 = time.time()\n","    yolo_df = yolo_results.pandas().xyxy[0]\n","    yolo_infer_time = t1 - t0\n","    # EfficientNetV2 åˆ†é¡ï¼ˆåƒ…é‡å° 'F' é¡åˆ¥ï¼‰\n","    f_detections = yolo_df[yolo_df['name'] == 'F'].copy()\n","    detailed_results = []\n","    effnet_total_time = 0\n","    for _, row in f_detections.iterrows():\n","        x1, y1, x2, y2 = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n","        pad_w = (x2 - x1) * CROP_PADDING_RATIO\n","        pad_h = (y2 - y1) * CROP_PADDING_RATIO\n","        x1_pad = max(0, x1 - pad_w)\n","        y1_pad = max(0, y1 - pad_h)\n","        x2_pad = min(img_w, x2 + pad_w)\n","        y2_pad = min(img_h, y2 + pad_h)\n","        cropped_image = original_image.crop((x1_pad, y1_pad, x2_pad, y2_pad))\n","        input_tensor = effnet_transforms(cropped_image).unsqueeze(0).to(device)\n","        t2 = time.time()\n","        output = effnet_model(input_tensor)\n","        probabilities = torch.softmax(output, dim=1)\n","        t3 = time.time()\n","        effnet_total_time += (t3 - t2)\n","        confidence, predicted_idx = torch.max(probabilities, 1)\n","        predicted_class = effnet_class_names[predicted_idx.item()]\n","        result_row = row.to_dict()\n","        result_row['effnet_class'] = predicted_class\n","        result_row['effnet_confidence'] = confidence.item()\n","        detailed_results.append(result_row)\n","    effnet_df = pd.DataFrame(detailed_results)\n","    return original_image, yolo_df, effnet_df, yolo_infer_time, effnet_total_time\n","\n","# 6. ä¸»æµç¨‹\n","def main():\n","    yolo_model, effnet_model, effnet_class_names, device = load_models()\n","    effnet_transforms = get_efficientnet_transforms()\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    %cd /content\n","    local_output_dir = f'results_{timestamp}'\n","    annotated_img_dir = os.path.join(local_output_dir, 'annotated_images')\n","    yolo_only_img_dir = os.path.join(local_output_dir, 'yolo_only_images')\n","    os.makedirs(annotated_img_dir, exist_ok=True)\n","    os.makedirs(yolo_only_img_dir, exist_ok=True)\n","    image_files = [f for f in os.listdir(TEST_IMAGES_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","    if not image_files:\n","        print(f\"âœ— åœ¨ '{TEST_IMAGES_DIR}' ä¸­æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡æª”æ¡ˆã€‚\")\n","        return\n","\n","    master_effnet_results = []\n","    master_yolo_results = []\n","    total_yolo_time = 0\n","    total_effnet_time = 0\n","    image_count = 0\n","\n","    for i, filename in enumerate(image_files):\n","        print(f\"\\n{'='*20} ({i+1}/{len(image_files)}) æ­£åœ¨è™•ç†: {filename} {'='*20}\")\n","        image_path = os.path.join(TEST_IMAGES_DIR, filename)\n","        original_image, yolo_df, effnet_df, yolo_time, effnet_time = process_image(\n","            image_path, yolo_model, effnet_model, effnet_transforms, effnet_class_names, device\n","        )\n","        if original_image is None:\n","            continue\n","        # ==================== é¡¯ç¤º YOLOv5s ç¬¬ä¸€éšæ®µçµæœ (åƒ…ç¹ªè£½ 'F' é¡) ====================\n","        print(\"\\nğŸ”µ [éšæ®µä¸€] YOLOv5 åŸå§‹åµæ¸¬çµæœï¼š\")\n","        if not yolo_df.empty:\n","            print(\" â”œâ”€ æ–‡å­—å ±è¡¨ (åµæ¸¬åˆ°çš„æ‰€æœ‰ç‰©ä»¶):\")\n","            print(yolo_df[['name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax']].to_string())\n","            yolo_f_only_df = yolo_df[yolo_df['name'] == 'F']\n","            if not yolo_f_only_df.empty:\n","                print(\" â””â”€ è¦–è¦ºåŒ–çµæœ (åƒ…é¡¯ç¤º 'F' é¡ç‰©ä»¶):\")\n","                yolo_annotated_image = draw_on_image(original_image, yolo_f_only_df)\n","                ipy_display(yolo_annotated_image)\n","                yolo_annotated_image.save(os.path.join(yolo_only_img_dir, f\"yolo_only_{filename}\"))\n","            else:\n","                print(\" â””â”€ è¦–è¦ºåŒ–çµæœ: YOLOv5 æœªåµæ¸¬åˆ° 'F' é¡ç‰©ä»¶ï¼Œå› æ­¤ç„¡é è¦½åœ–ã€‚\")\n","            yolo_df['source_image'] = filename\n","            master_yolo_results.append(yolo_df)\n","        else:\n","            print(\" â””â”€ æœªåµæ¸¬åˆ°ä»»ä½•ç‰©ä»¶ã€‚\")\n","\n","        # ==================== é›™éšæ®µçµåˆæœ€çµ‚çµæœ ====================\n","        print(\"\\nâœ… [æœ€çµ‚çµæœ] é›™éšæ®µçµåˆè¾¨è­˜ï¼š\")\n","        if not effnet_df.empty:\n","            effnet_df['source_image'] = filename\n","            master_effnet_results.append(effnet_df)\n","            final_annotated_image = draw_on_image(original_image, effnet_df)\n","            final_annotated_image.save(os.path.join(annotated_img_dir, f\"annotated_{filename}\"))\n","            print(f\" â”œâ”€ EfficientNetV2 å·²åˆ†é¡ {len(effnet_df)} å€‹ 'F' ç‰©ä»¶ï¼š\")\n","            print(effnet_df[['effnet_class', 'effnet_confidence', 'xmin', 'ymin', 'xmax', 'ymax']].to_string())\n","            print(\" â””â”€ è¦–è¦ºåŒ–çµæœ:\")\n","            ipy_display(final_annotated_image)\n","        else:\n","            print(\" â””â”€ ç„¡ç¬¬äºŒéšæ®µåˆ†é¡çµæœ (æœªåµæ¸¬åˆ° 'F' é¡ç‰©ä»¶)ã€‚\")\n","        total_yolo_time += yolo_time\n","        total_effnet_time += effnet_time\n","        image_count += 1\n","\n","    # çµ±è¨ˆæ¨è«–é€Ÿåº¦\n","    if image_count > 0:\n","        print(f\"\\n====== æ¨è«–é€Ÿåº¦çµ±è¨ˆ ======\")\n","        print(f\"YOLOv5s å¹³å‡å–®å¼µæ¨è«–æ™‚é–“ï¼š{total_yolo_time / image_count:.4f} ç§’\")\n","        print(f\"EfficientNetV2s å¹³å‡å–®å¼µæ¨è«–æ™‚é–“ï¼š{total_effnet_time / image_count:.4f} ç§’\")\n","        print(f\"é›™éšæ®µåˆè¨ˆå¹³å‡å–®å¼µæ¨è«–æ™‚é–“ï¼š{(total_yolo_time + total_effnet_time) / image_count:.4f} ç§’\")\n","        print(f\"YOLOv5s + EfficientNetV2s å¹³å‡ FPSï¼š{image_count / (total_yolo_time + total_effnet_time):.2f}\")\n","\n","    # å„²å­˜çµæœ CSV\n","    if master_yolo_results:\n","        yolo_all_df = pd.concat(master_yolo_results, ignore_index=True)\n","        yolo_csv_path = os.path.join(local_output_dir, 'yolo_all_results.csv')\n","        yolo_all_df.to_csv(yolo_csv_path, index=False, encoding='utf-8-sig')\n","    if master_effnet_results:\n","        effnet_all_df = pd.concat(master_effnet_results, ignore_index=True)\n","        effnet_csv_path = os.path.join(local_output_dir, 'effnet_results.csv')\n","        effnet_all_df.to_csv(effnet_csv_path, index=False, encoding='utf-8-sig')\n","\n","    # æ‰“åŒ…æ¨™è¨»åœ–èˆ‡çµæœ\n","    if os.path.exists(local_output_dir) and os.listdir(local_output_dir):\n","        print(\"\\nâ€º æ­£åœ¨æ‰“åŒ…æ‰€æœ‰æ¨™è¨»åœ–ç‰‡èˆ‡çµæœ...\")\n","        shutil.make_archive(local_output_dir, 'zip', local_output_dir)\n","        zip_path = f\"/content/{local_output_dir}.zip\"\n","        shutil.copy(zip_path, OUTPUT_DIR_ON_DRIVE)\n","        print(f\"âœ“ æ‰“åŒ…å®Œæˆï¼ŒZIP æª”å·²å„²å­˜åˆ°æ‚¨çš„é›²ç«¯ï¼š{os.path.join(OUTPUT_DIR_ON_DRIVE, os.path.basename(zip_path))}\")\n","        shutil.rmtree(local_output_dir)\n","        os.remove(zip_path)\n","    else:\n","        print(\"\\nâ€º æ²’æœ‰ç”¢ç”Ÿä»»ä½•è¼¸å‡ºçµæœï¼Œç„¡éœ€æ‰“åŒ…ã€‚\")\n","\n","if __name__ == '__main__':\n","    main()\n"]}]}