{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM2EbjhEqC+gexHjV6hFeRp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EpALH6CFbeIR2G4tJEphjG3MgzV4oIwy"},"id":"T1NVCMmBA_YL","executionInfo":{"status":"ok","timestamp":1753438023827,"user_tz":-480,"elapsed":120469,"user":{"displayName":"李柏駿","userId":"07522532513227506161"}},"outputId":"87856d19-9e85-48a4-c9fd-d66e0ea5a20c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# ==============================================================================\n","# YOLOv5s + EfficientNetV2s 雙階段辨識流程（F/S/V三分類＋推論速度＋自動打包）\n","# ==============================================================================\n","\n","import os\n","import shutil\n","import time\n","from datetime import datetime\n","from google.colab import drive\n","import torch\n","import timm\n","import cv2\n","import pandas as pd\n","import numpy as np\n","from PIL import Image, ImageDraw, ImageFont\n","import torchvision.transforms as transforms\n","from IPython.display import display as ipy_display\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# 1. 掛載 Google Drive\n","drive.mount('/content/drive')\n","\n","# ====== 克隆 YOLOv5 程式庫 ======\n","if not os.path.exists('/content/yolov5'):\n","    !git clone https://github.com/ultralytics/yolov5.git /content/yolov5\n","    %cd /content/yolov5\n","    !pip install -r requirements.txt\n","    %cd /content\n","\n","# 2. 使用者設定區\n","YOLO_MODEL_PATH = '/content/drive/MyDrive/DualStage-DefectAI/程式/yolo+eff模型與測試集/yolo_best.pt'\n","EFFICIENTNET_MODEL_PATH = '/content/drive/MyDrive/DualStage-DefectAI/程式/yolo+eff模型與測試集/eff_best.pth'\n","TEST_IMAGES_DIR = '/content/drive/MyDrive/DualStage-DefectAI/程式/yolo+eff模型與測試集/測試集/images'\n","OUTPUT_DIR_ON_DRIVE = '/content/drive/MyDrive/DualStage-DefectAI/輸出/yolo+efficientnet'\n","YOLO_CONF_THRESHOLD = 0.2\n","CROP_PADDING_RATIO = 0.1\n","\n","# 3. 檢查路徑\n","paths_to_check = {\n","    \"YOLO 模型\": YOLO_MODEL_PATH,\n","    \"EfficientNetV2 模型\": EFFICIENTNET_MODEL_PATH,\n","    \"測試圖片資料夾\": TEST_IMAGES_DIR,\n","}\n","all_paths_ok = True\n","for name, path in paths_to_check.items():\n","    if not os.path.exists(path):\n","        print(f\"✗ 錯誤: 找不到 {name} -> {path}\")\n","        all_paths_ok = False\n","if not all_paths_ok:\n","    raise FileNotFoundError(\"有路徑設定錯誤，請檢查上方訊息！\")\n","\n","# 4. 載入模型\n","@torch.no_grad()\n","def load_models():\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    yolo_model = torch.hub.load('/content/yolov5', 'custom', path=YOLO_MODEL_PATH, source='local')\n","    yolo_model.conf = YOLO_CONF_THRESHOLD\n","    yolo_model.to(device)\n","    yolo_model.eval()\n","    # 此處將class_names改為三類\n","    checkpoint = torch.load(EFFICIENTNET_MODEL_PATH, map_location=device)\n","    effnet_class_names = checkpoint.get('class_names', ['F', 'S', 'V'])\n","    num_classes = len(effnet_class_names)\n","    effnet_model = timm.create_model('tf_efficientnetv2_s.in1k', pretrained=False, num_classes=num_classes)\n","    effnet_model.load_state_dict(checkpoint['model_state_dict'])\n","    effnet_model.to(device)\n","    effnet_model.eval()\n","    return yolo_model, effnet_model, effnet_class_names, device\n","\n","def get_efficientnet_transforms():\n","    return transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","def draw_on_image(image, detections_df):\n","    img_draw = image.copy()\n","    draw = ImageDraw.Draw(img_draw)\n","    try:\n","        font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", 20)\n","    except IOError:\n","        font = ImageFont.load_default()\n","\n","    for _, row in detections_df.iterrows():\n","        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n","        # 判斷階段\n","        if 'effnet_class' in row:\n","            effnet_class = row.get('effnet_class', '')\n","            # === 三分類顏色標示：紅F 藍S 橘V ===\n","            if effnet_class == 'F':\n","                color = 'red'\n","            elif effnet_class == 'S':\n","                color = 'blue'\n","            elif effnet_class == 'V':\n","                color = 'orange'\n","            else:\n","                color = 'gray'\n","            confidence = row.get('effnet_confidence', 0)\n","            label = f\"{effnet_class}: {confidence:.2%}\"\n","        else:\n","            yolo_class = row['name']\n","            color = 'red' if row['name'] == 'F' else 'blue'\n","            confidence = row.get('confidence', 0)\n","            label = f\"{yolo_class}: {confidence:.2%}\"\n","\n","        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n","        try:\n","            text_bbox = draw.textbbox((0, 0), label, font=font)\n","            text_w = text_bbox[2] - text_bbox[0]\n","            text_h = text_bbox[3] - text_bbox[1]\n","            text_y_pos = y1 - text_h - 10\n","            if text_y_pos < 0: text_y_pos = y1 + 5\n","            draw.rectangle([x1, text_y_pos, x1 + text_w + 10, text_y_pos + text_h + 5], fill=color)\n","            draw.text((x1 + 5, text_y_pos), label, fill='white', font=font)\n","        except AttributeError:\n","            draw.text((x1 + 5, y1 - 20), label, fill=color, font=font)\n","    return img_draw\n","\n","# 5. 單張圖片處理（同時回傳推論時間）\n","@torch.no_grad()\n","def process_image(image_path, yolo_model, effnet_model, effnet_transforms, effnet_class_names, device):\n","    try:\n","        original_image = Image.open(image_path).convert('RGB')\n","    except Exception as e:\n","        print(f\"✗ 無法讀取圖片 {os.path.basename(image_path)}: {e}\")\n","        return None, pd.DataFrame(), pd.DataFrame(), 0, 0\n","    img_w, img_h = original_image.size\n","    # YOLOv5s 物件偵測\n","    t0 = time.time()\n","    yolo_results = yolo_model(original_image)\n","    t1 = time.time()\n","    yolo_df = yolo_results.pandas().xyxy[0]\n","    yolo_infer_time = t1 - t0\n","    # EfficientNetV2 分類（僅針對 'F' 類別）\n","    f_detections = yolo_df[yolo_df['name'] == 'F'].copy()\n","    detailed_results = []\n","    effnet_total_time = 0\n","    for _, row in f_detections.iterrows():\n","        x1, y1, x2, y2 = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n","        pad_w = (x2 - x1) * CROP_PADDING_RATIO\n","        pad_h = (y2 - y1) * CROP_PADDING_RATIO\n","        x1_pad = max(0, x1 - pad_w)\n","        y1_pad = max(0, y1 - pad_h)\n","        x2_pad = min(img_w, x2 + pad_w)\n","        y2_pad = min(img_h, y2 + pad_h)\n","        cropped_image = original_image.crop((x1_pad, y1_pad, x2_pad, y2_pad))\n","        input_tensor = effnet_transforms(cropped_image).unsqueeze(0).to(device)\n","        t2 = time.time()\n","        output = effnet_model(input_tensor)\n","        probabilities = torch.softmax(output, dim=1)\n","        t3 = time.time()\n","        effnet_total_time += (t3 - t2)\n","        confidence, predicted_idx = torch.max(probabilities, 1)\n","        predicted_class = effnet_class_names[predicted_idx.item()]\n","        result_row = row.to_dict()\n","        result_row['effnet_class'] = predicted_class\n","        result_row['effnet_confidence'] = confidence.item()\n","        detailed_results.append(result_row)\n","    effnet_df = pd.DataFrame(detailed_results)\n","    return original_image, yolo_df, effnet_df, yolo_infer_time, effnet_total_time\n","\n","# 6. 主流程\n","def main():\n","    yolo_model, effnet_model, effnet_class_names, device = load_models()\n","    effnet_transforms = get_efficientnet_transforms()\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    %cd /content\n","    local_output_dir = f'results_{timestamp}'\n","    annotated_img_dir = os.path.join(local_output_dir, 'annotated_images')\n","    yolo_only_img_dir = os.path.join(local_output_dir, 'yolo_only_images')\n","    os.makedirs(annotated_img_dir, exist_ok=True)\n","    os.makedirs(yolo_only_img_dir, exist_ok=True)\n","    image_files = [f for f in os.listdir(TEST_IMAGES_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","    if not image_files:\n","        print(f\"✗ 在 '{TEST_IMAGES_DIR}' 中找不到任何圖片檔案。\")\n","        return\n","\n","    master_effnet_results = []\n","    master_yolo_results = []\n","    total_yolo_time = 0\n","    total_effnet_time = 0\n","    image_count = 0\n","\n","    for i, filename in enumerate(image_files):\n","        print(f\"\\n{'='*20} ({i+1}/{len(image_files)}) 正在處理: {filename} {'='*20}\")\n","        image_path = os.path.join(TEST_IMAGES_DIR, filename)\n","        original_image, yolo_df, effnet_df, yolo_time, effnet_time = process_image(\n","            image_path, yolo_model, effnet_model, effnet_transforms, effnet_class_names, device\n","        )\n","        if original_image is None:\n","            continue\n","        # ==================== 顯示 YOLOv5s 第一階段結果 (僅繪製 'F' 類) ====================\n","        print(\"\\n🔵 [階段一] YOLOv5 原始偵測結果：\")\n","        if not yolo_df.empty:\n","            print(\" ├─ 文字報表 (偵測到的所有物件):\")\n","            print(yolo_df[['name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax']].to_string())\n","            yolo_f_only_df = yolo_df[yolo_df['name'] == 'F']\n","            if not yolo_f_only_df.empty:\n","                print(\" └─ 視覺化結果 (僅顯示 'F' 類物件):\")\n","                yolo_annotated_image = draw_on_image(original_image, yolo_f_only_df)\n","                ipy_display(yolo_annotated_image)\n","                yolo_annotated_image.save(os.path.join(yolo_only_img_dir, f\"yolo_only_{filename}\"))\n","            else:\n","                print(\" └─ 視覺化結果: YOLOv5 未偵測到 'F' 類物件，因此無預覽圖。\")\n","            yolo_df['source_image'] = filename\n","            master_yolo_results.append(yolo_df)\n","        else:\n","            print(\" └─ 未偵測到任何物件。\")\n","\n","        # ==================== 雙階段結合最終結果 ====================\n","        print(\"\\n✅ [最終結果] 雙階段結合辨識：\")\n","        if not effnet_df.empty:\n","            effnet_df['source_image'] = filename\n","            master_effnet_results.append(effnet_df)\n","            final_annotated_image = draw_on_image(original_image, effnet_df)\n","            final_annotated_image.save(os.path.join(annotated_img_dir, f\"annotated_{filename}\"))\n","            print(f\" ├─ EfficientNetV2 已分類 {len(effnet_df)} 個 'F' 物件：\")\n","            print(effnet_df[['effnet_class', 'effnet_confidence', 'xmin', 'ymin', 'xmax', 'ymax']].to_string())\n","            print(\" └─ 視覺化結果:\")\n","            ipy_display(final_annotated_image)\n","        else:\n","            print(\" └─ 無第二階段分類結果 (未偵測到 'F' 類物件)。\")\n","        total_yolo_time += yolo_time\n","        total_effnet_time += effnet_time\n","        image_count += 1\n","\n","    # 統計推論速度\n","    if image_count > 0:\n","        print(f\"\\n====== 推論速度統計 ======\")\n","        print(f\"YOLOv5s 平均單張推論時間：{total_yolo_time / image_count:.4f} 秒\")\n","        print(f\"EfficientNetV2s 平均單張推論時間：{total_effnet_time / image_count:.4f} 秒\")\n","        print(f\"雙階段合計平均單張推論時間：{(total_yolo_time + total_effnet_time) / image_count:.4f} 秒\")\n","        print(f\"YOLOv5s + EfficientNetV2s 平均 FPS：{image_count / (total_yolo_time + total_effnet_time):.2f}\")\n","\n","    # 儲存結果 CSV\n","    if master_yolo_results:\n","        yolo_all_df = pd.concat(master_yolo_results, ignore_index=True)\n","        yolo_csv_path = os.path.join(local_output_dir, 'yolo_all_results.csv')\n","        yolo_all_df.to_csv(yolo_csv_path, index=False, encoding='utf-8-sig')\n","    if master_effnet_results:\n","        effnet_all_df = pd.concat(master_effnet_results, ignore_index=True)\n","        effnet_csv_path = os.path.join(local_output_dir, 'effnet_results.csv')\n","        effnet_all_df.to_csv(effnet_csv_path, index=False, encoding='utf-8-sig')\n","\n","    # 打包標註圖與結果\n","    if os.path.exists(local_output_dir) and os.listdir(local_output_dir):\n","        print(\"\\n› 正在打包所有標註圖片與結果...\")\n","        shutil.make_archive(local_output_dir, 'zip', local_output_dir)\n","        zip_path = f\"/content/{local_output_dir}.zip\"\n","        shutil.copy(zip_path, OUTPUT_DIR_ON_DRIVE)\n","        print(f\"✓ 打包完成，ZIP 檔已儲存到您的雲端：{os.path.join(OUTPUT_DIR_ON_DRIVE, os.path.basename(zip_path))}\")\n","        shutil.rmtree(local_output_dir)\n","        os.remove(zip_path)\n","    else:\n","        print(\"\\n› 沒有產生任何輸出結果，無需打包。\")\n","\n","if __name__ == '__main__':\n","    main()\n"]}]}